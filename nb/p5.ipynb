{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035c4d0-8921-42e3-bf5a-4ecf2668a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casey Reyes & Joaquin Feria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e51bfa4-0f2e-47f4-816b-d50f77d508d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -D dfs.replication=1 -cp -f data/*.csv hdfs://nn:9000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc753b80-4100-49a4-8cc1-c7599c81c042",
   "metadata": {},
   "source": [
    "# Part 1: Filtering: RDDs, DataFrames, and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a821c756-cbc1-4439-9108-bccd650fa784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b8544a80-3245-4b51-86dd-062cffb0290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1: how many banks contain the word \"first\" in their name, ignoring case? Use an RDD to answer.\n",
    "\n",
    "# TODO: modify to treat the first row as a header\n",
    "# TODO: modify to infer the schema\n",
    "banks_df = spark.read.csv(\"hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\")\n",
    "rdd = banks_df.rdd\n",
    "filtered_banks = rdd.filter(lambda x: \"first\" in x[0].lower())\n",
    "filtered_banks.count()\n",
    "\n",
    "# filtered_bank_names = filtered_banks.collect()\n",
    "# for name in filtered_bank_names:\n",
    "#     print(name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b88f2a05-8f26-4bc3-8774-d7f76297f533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2 how many banks contain the word \"first\" in their name, ignoring case? Use a DataFrame to answer.\n",
    "from pyspark.sql.functions import expr, col, lower\n",
    "\n",
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .load(\"hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\"))\n",
    "\n",
    "col(\"respondent_name\")\n",
    "expr(\"respondent_name\")\n",
    "\n",
    "filtered_df = df.filter(lower(expr(\"respondent_name\")).like(\"%first%\"))\n",
    "filtered_pandas_df = filtered_df.select(\"respondent_name\")\n",
    "filtered_pandas_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c0e5f12-e6d1-4487-a5b9-e7f73e2376ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3 how many banks contain the word \"first\" in their name, ignoring case? Use Spark SQL to answer.\n",
    "\n",
    "banks_df.write.saveAsTable(\"banks\", mode=\"overwrite\")\n",
    "\n",
    "df\n",
    "df.createOrReplaceTempView(\"names\")\n",
    "df.withColumnRenamed(\"respondent_name\", \"name\").createOrReplaceTempView(\"names\")\n",
    "filtered_df = spark.sql(\"SELECT * FROM names WHERE LOWER(name) LIKE '%first%'\")\n",
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf366f-32af-4056-a348-f5da028f744b",
   "metadata": {},
   "source": [
    "## Part 2: Hive Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4a9d6-3cfa-4db4-b0ec-7210f063fb52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
