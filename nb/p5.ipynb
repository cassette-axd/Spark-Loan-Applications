{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1035c4d0-8921-42e3-bf5a-4ecf2668a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casey Reyes & Joaquin Feria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e51bfa4-0f2e-47f4-816b-d50f77d508d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -D dfs.replication=1 -cp -f data/*.csv hdfs://nn:9000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc753b80-4100-49a4-8cc1-c7599c81c042",
   "metadata": {},
   "source": [
    "# Part 1: Filtering: RDDs, DataFrames, and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a821c756-cbc1-4439-9108-bccd650fa784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 01:30:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8544a80-3245-4b51-86dd-062cffb0290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1: how many banks contain the word \"first\" in their name, ignoring case? Use an RDD to answer.\n",
    "\n",
    "# TODO: modify to treat the first row as a header\n",
    "# TODO: modify to infer the schema\n",
    "banks_df = (spark.read.format(\"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .load(\"hdfs://nn:9000/arid2017_to_lei_xref_csv.csv\"))\n",
    "rdd = banks_df.rdd\n",
    "filtered_banks = rdd.filter(lambda x: \"first\" in x[0].lower())\n",
    "filtered_banks.count()\n",
    "\n",
    "# filtered_bank_names = filtered_banks.collect()\n",
    "# for name in filtered_bank_names:\n",
    "#     print(name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88f2a05-8f26-4bc3-8774-d7f76297f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2 how many banks contain the word \"first\" in their name, ignoring case? Use a DataFrame to answer.\n",
    "from pyspark.sql.functions import expr, col, lower\n",
    "\n",
    "col(\"respondent_name\")\n",
    "expr(\"respondent_name\")\n",
    "\n",
    "filtered_df = banks_df.filter(lower(expr(\"respondent_name\")).like(\"%first%\"))\n",
    "filtered_pandas_df = filtered_df.select(\"respondent_name\")\n",
    "filtered_pandas_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0e5f12-e6d1-4487-a5b9-e7f73e2376ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 01:31:22 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/11/09 01:31:22 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "23/11/09 01:31:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "23/11/09 01:31:27 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.3\n",
      "23/11/09 01:31:29 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "23/11/09 01:31:29 WARN HadoopFSUtils: The directory hdfs://nn:9000/user/hive/warehouse/banks was not found. Was it deleted very recently?\n",
      "23/11/09 01:31:31 WARN FileUtils: File does not exist: hdfs://nn:9000/user/hive/warehouse/banks; Force to delete it.\n",
      "23/11/09 01:31:31 ERROR FileUtils: Failed to delete hdfs://nn:9000/user/hive/warehouse/banks\n",
      "23/11/09 01:31:34 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "23/11/09 01:31:34 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "23/11/09 01:31:34 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/11/09 01:31:34 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3 how many banks contain the word \"first\" in their name, ignoring case? Use Spark SQL to answer.\n",
    "\n",
    "banks_df.write.saveAsTable(\"banks\", mode=\"overwrite\")\n",
    "\n",
    "banks_df\n",
    "banks_df.createOrReplaceTempView(\"names\")\n",
    "banks_df.withColumnRenamed(\"respondent_name\", \"name\").createOrReplaceTempView(\"names\")\n",
    "filtered_df = spark.sql(\"SELECT * FROM names WHERE LOWER(name) LIKE '%first%'\")\n",
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf366f-32af-4056-a348-f5da028f744b",
   "metadata": {},
   "source": [
    "## Part 2: Hive Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab4a9d6-3cfa-4db4-b0ec-7210f063fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 01:31:51 WARN HadoopFSUtils: The directory hdfs://nn:9000/user/hive/warehouse/loans was not found. Was it deleted very recently?\n",
      "23/11/09 01:31:51 WARN FileUtils: File does not exist: hdfs://nn:9000/user/hive/warehouse/loans; Force to delete it.\n",
      "23/11/09 01:31:51 ERROR FileUtils: Failed to delete hdfs://nn:9000/user/hive/warehouse/loans\n",
      "23/11/09 01:31:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/11/09 01:32:19 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `spark_catalog`.`default`.`loans` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    }
   ],
   "source": [
    "loans_df = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .load(\"hdfs://nn:9000/hdma-wi-2021.csv\"))\n",
    "            # .createOrReplaceTempView(\"codes\"))\n",
    "(loans_df.write.format(\"csv\")\n",
    "            .bucketBy(8, 'county_code')\n",
    "            .mode(\"overwrite\")\n",
    "            .saveAsTable('loans'))\n",
    "\n",
    "# loans_df.printSchema\n",
    "views_list = [\"ethnicity\", \"race\", \"sex\", \"states\", \"counties\", \"tracts\", \"action_taken\", \"denial_reason\", \"loan_type\", \"loan_purpose\", \"preapproval\", \"property_type\"]\n",
    "for view in views_list:\n",
    "    loans_df.createOrReplaceTempView(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ce6eaf-ed70-4209-8f81-b8e591a84f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+\n",
      "|namespace|    tableName|isTemporary|\n",
      "+---------+-------------+-----------+\n",
      "|  default|        banks|      false|\n",
      "|  default|        loans|      false|\n",
      "|         | action_taken|       true|\n",
      "|         |     counties|       true|\n",
      "|         |denial_reason|       true|\n",
      "|         |    ethnicity|       true|\n",
      "|         | loan_purpose|       true|\n",
      "|         |    loan_type|       true|\n",
      "|         |        names|       true|\n",
      "|         |  preapproval|       true|\n",
      "|         |property_type|       true|\n",
      "|         |         race|       true|\n",
      "|         |          sex|       true|\n",
      "|         |       states|       true|\n",
      "|         |       tracts|       true|\n",
      "+---------+-------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'banks': False,\n",
       " 'loans': False,\n",
       " 'action_taken': True,\n",
       " 'counties': True,\n",
       " 'denial_reason': True,\n",
       " 'ethnicity': True,\n",
       " 'loan_purpose': True,\n",
       " 'loan_type': True,\n",
       " 'names': True,\n",
       " 'preapproval': True,\n",
       " 'property_type': True,\n",
       " 'race': True,\n",
       " 'sex': True,\n",
       " 'states': True,\n",
       " 'tracts': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4 what tables are in our warehouse?\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show()\n",
    "tables_df = spark.sql(\"SHOW TABLES\")\n",
    "table_list = tables_df.collect()\n",
    "table_dict = {row['tableName']: row['isTemporary'] for row in table_list}\n",
    "table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ae96cd-e15d-48e0-a198-96c6a0a3d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19739"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5 how many loan applications has the bank \"University of Wisconsin Credit Union\" received in 2020 in this dataset?\n",
    "\n",
    "bank_name = \"University of Wisconsin Credit Union\"\n",
    "total_df = banks_df.join(\n",
    "    loans_df,\n",
    "    loans_df[\"lei\"] == banks_df[\"lei_2020\"],\n",
    "    \"inner\"\n",
    ").filter(banks_df[\"respondent_name\"] == bank_name)\n",
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1457f9c9-91da-43b1-babc-21647100f208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (7)\n",
      "+- BroadcastHashJoin Inner BuildLeft (6)\n",
      "   :- BroadcastExchange (3)\n",
      "   :  +- Filter (2)\n",
      "   :     +- Scan csv  (1)\n",
      "   +- Filter (5)\n",
      "      +- Scan csv  (4)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [5]: [respondent_name#17, arid_2017#18, lei_2018#19, lei_2019#20, lei_2020#21]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [hdfs://nn:9000/arid2017_to_lei_xref_csv.csv]\n",
      "PushedFilters: [IsNotNull(respondent_name), EqualTo(respondent_name,University of Wisconsin Credit Union), IsNotNull(lei_2020)]\n",
      "ReadSchema: struct<respondent_name:string,arid_2017:string,lei_2018:string,lei_2019:string,lei_2020:string>\n",
      "\n",
      "(2) Filter\n",
      "Input [5]: [respondent_name#17, arid_2017#18, lei_2018#19, lei_2019#20, lei_2020#21]\n",
      "Condition : ((isnotnull(respondent_name#17) AND (respondent_name#17 = University of Wisconsin Credit Union)) AND isnotnull(lei_2020#21))\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [5]: [respondent_name#17, arid_2017#18, lei_2018#19, lei_2019#20, lei_2020#21]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[4, string, false]),false), [plan_id=366]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [99]: [activity_year#100, lei#101, derived_msa-md#102, state_code#103, county_code#104, census_tract#105, conforming_loan_limit#106, derived_loan_product_type#107, derived_dwelling_category#108, derived_ethnicity#109, derived_race#110, derived_sex#111, action_taken#112, purchaser_type#113, preapproval#114, loan_type#115, loan_purpose#116, lien_status#117, reverse_mortgage#118, open-end_line_of_credit#119, business_or_commercial_purpose#120, loan_amount#121, loan_to_value_ratio#122, interest_rate#123, rate_spread#124, hoepa_status#125, total_loan_costs#126, total_points_and_fees#127, origination_charges#128, discount_points#129, lender_credits#130, loan_term#131, prepayment_penalty_term#132, intro_rate_period#133, negative_amortization#134, interest_only_payment#135, balloon_payment#136, other_nonamortizing_features#137, property_value#138, construction_method#139, occupancy_type#140, manufactured_home_secured_property_type#141, manufactured_home_land_property_interest#142, total_units#143, multifamily_affordable_units#144, income#145, debt_to_income_ratio#146, applicant_credit_score_type#147, co-applicant_credit_score_type#148, applicant_ethnicity-1#149, applicant_ethnicity-2#150, applicant_ethnicity-3#151, applicant_ethnicity-4#152, applicant_ethnicity-5#153, co-applicant_ethnicity-1#154, co-applicant_ethnicity-2#155, co-applicant_ethnicity-3#156, co-applicant_ethnicity-4#157, co-applicant_ethnicity-5#158, applicant_ethnicity_observed#159, co-applicant_ethnicity_observed#160, applicant_race-1#161, applicant_race-2#162, applicant_race-3#163, applicant_race-4#164, applicant_race-5#165, co-applicant_race-1#166, co-applicant_race-2#167, co-applicant_race-3#168, co-applicant_race-4#169, co-applicant_race-5#170, applicant_race_observed#171, co-applicant_race_observed#172, applicant_sex#173, co-applicant_sex#174, applicant_sex_observed#175, co-applicant_sex_observed#176, applicant_age#177, co-applicant_age#178, applicant_age_above_62#179, co-applicant_age_above_62#180, submission_of_application#181, initially_payable_to_institution#182, aus-1#183, aus-2#184, aus-3#185, aus-4#186, aus-5#187, denial_reason-1#188, denial_reason-2#189, denial_reason-3#190, denial_reason-4#191, tract_population#192, tract_minority_population_percent#193, ffiec_msa_md_median_family_income#194, tract_to_msa_income_percentage#195, tract_owner_occupied_units#196, tract_one_to_four_family_homes#197, tract_median_age_of_housing_units#198]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [hdfs://nn:9000/hdma-wi-2021.csv]\n",
      "PushedFilters: [IsNotNull(lei)]\n",
      "ReadSchema: struct<activity_year:int,lei:string,derived_msa-md:int,state_code:string,county_code:string,census_tract:string,conforming_loan_limit:string,derived_loan_product_type:string,derived_dwelling_category:string,derived_ethnicity:string,derived_race:string,derived_sex:string,action_taken:int,purchaser_type:int,preapproval:int,loan_type:int,loan_purpose:int,lien_status:int,reverse_mortgage:int,open-end_line_of_credit:int,business_or_commercial_purpose:int,loan_amount:double,loan_to_value_ratio:string,interest_rate:string,rate_spread:string,hoepa_status:int,total_loan_costs:string,total_points_and_fees:string,origination_charges:string,discount_points:string,lender_credits:string,loan_term:string,prepayment_penalty_term:string,intro_rate_period:string,negative_amortization:int,interest_only_payment:int,balloon_payment:int,other_nonamortizing_features:int,property_value:string,construction_method:int,occupancy_type:int,manufactured_home_secured_property_type:int,manufactured_home_land_property_interest:int,total_units:string,multifamily_affordable_units:string,income:string,debt_to_income_ratio:string,applicant_credit_score_type:int,co-applicant_credit_score_type:int,applicant_ethnicity-1:int,applicant_ethnicity-2:int,applicant_ethnicity-3:int,applicant_ethnicity-4:int,applicant_ethnicity-5:int,co-applicant_ethnicity-1:int,co-applicant_ethnicity-2:int,co-applicant_ethnicity-3:int,co-applicant_ethnicity-4:int,co-applicant_ethnicity-5:string,applicant_ethnicity_observed:int,co-applicant_ethnicity_observed:int,applicant_race-1:int,applicant_race-2:int,applicant_race-3:int,applicant_race-4:int,applicant_race-5:int,co-applicant_race-1:int,co-applicant_race-2:int,co-applicant_race-3:int,co-applicant_race-4:int,co-applicant_race-5:int,applicant_race_observed:int,co-applicant_race_observed:int,applicant_sex:int,co-applicant_sex:int,applicant_sex_observed:int,co-applicant_sex_observed:int,applicant_age:string,co-applicant_age:string,applicant_age_above_62:string,co-applicant_age_above_62:string,submission_of_application:int,initially_payable_to_institution:int,aus-1:int,aus-2:int,aus-3:int,aus-4:int,aus-5:int,denial_reason-1:int,denial_reason-2:int,denial_reason-3:int,denial_reason-4:int,tract_population:int,tract_minority_population_percent:double,ffiec_msa_md_median_family_income:int,tract_to_msa_income_percentage:int,tract_owner_occupied_units:int,tract_one_to_four_family_homes:int,tract_median_age_of_housing_units:int>\n",
      "\n",
      "(5) Filter\n",
      "Input [99]: [activity_year#100, lei#101, derived_msa-md#102, state_code#103, county_code#104, census_tract#105, conforming_loan_limit#106, derived_loan_product_type#107, derived_dwelling_category#108, derived_ethnicity#109, derived_race#110, derived_sex#111, action_taken#112, purchaser_type#113, preapproval#114, loan_type#115, loan_purpose#116, lien_status#117, reverse_mortgage#118, open-end_line_of_credit#119, business_or_commercial_purpose#120, loan_amount#121, loan_to_value_ratio#122, interest_rate#123, rate_spread#124, hoepa_status#125, total_loan_costs#126, total_points_and_fees#127, origination_charges#128, discount_points#129, lender_credits#130, loan_term#131, prepayment_penalty_term#132, intro_rate_period#133, negative_amortization#134, interest_only_payment#135, balloon_payment#136, other_nonamortizing_features#137, property_value#138, construction_method#139, occupancy_type#140, manufactured_home_secured_property_type#141, manufactured_home_land_property_interest#142, total_units#143, multifamily_affordable_units#144, income#145, debt_to_income_ratio#146, applicant_credit_score_type#147, co-applicant_credit_score_type#148, applicant_ethnicity-1#149, applicant_ethnicity-2#150, applicant_ethnicity-3#151, applicant_ethnicity-4#152, applicant_ethnicity-5#153, co-applicant_ethnicity-1#154, co-applicant_ethnicity-2#155, co-applicant_ethnicity-3#156, co-applicant_ethnicity-4#157, co-applicant_ethnicity-5#158, applicant_ethnicity_observed#159, co-applicant_ethnicity_observed#160, applicant_race-1#161, applicant_race-2#162, applicant_race-3#163, applicant_race-4#164, applicant_race-5#165, co-applicant_race-1#166, co-applicant_race-2#167, co-applicant_race-3#168, co-applicant_race-4#169, co-applicant_race-5#170, applicant_race_observed#171, co-applicant_race_observed#172, applicant_sex#173, co-applicant_sex#174, applicant_sex_observed#175, co-applicant_sex_observed#176, applicant_age#177, co-applicant_age#178, applicant_age_above_62#179, co-applicant_age_above_62#180, submission_of_application#181, initially_payable_to_institution#182, aus-1#183, aus-2#184, aus-3#185, aus-4#186, aus-5#187, denial_reason-1#188, denial_reason-2#189, denial_reason-3#190, denial_reason-4#191, tract_population#192, tract_minority_population_percent#193, ffiec_msa_md_median_family_income#194, tract_to_msa_income_percentage#195, tract_owner_occupied_units#196, tract_one_to_four_family_homes#197, tract_median_age_of_housing_units#198]\n",
      "Condition : isnotnull(lei#101)\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [lei_2020#21]\n",
      "Right keys [1]: [lei#101]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) AdaptiveSparkPlan\n",
      "Output [104]: [respondent_name#17, arid_2017#18, lei_2018#19, lei_2019#20, lei_2020#21, activity_year#100, lei#101, derived_msa-md#102, state_code#103, county_code#104, census_tract#105, conforming_loan_limit#106, derived_loan_product_type#107, derived_dwelling_category#108, derived_ethnicity#109, derived_race#110, derived_sex#111, action_taken#112, purchaser_type#113, preapproval#114, loan_type#115, loan_purpose#116, lien_status#117, reverse_mortgage#118, open-end_line_of_credit#119, business_or_commercial_purpose#120, loan_amount#121, loan_to_value_ratio#122, interest_rate#123, rate_spread#124, hoepa_status#125, total_loan_costs#126, total_points_and_fees#127, origination_charges#128, discount_points#129, lender_credits#130, loan_term#131, prepayment_penalty_term#132, intro_rate_period#133, negative_amortization#134, interest_only_payment#135, balloon_payment#136, other_nonamortizing_features#137, property_value#138, construction_method#139, occupancy_type#140, manufactured_home_secured_property_type#141, manufactured_home_land_property_interest#142, total_units#143, multifamily_affordable_units#144, income#145, debt_to_income_ratio#146, applicant_credit_score_type#147, co-applicant_credit_score_type#148, applicant_ethnicity-1#149, applicant_ethnicity-2#150, applicant_ethnicity-3#151, applicant_ethnicity-4#152, applicant_ethnicity-5#153, co-applicant_ethnicity-1#154, co-applicant_ethnicity-2#155, co-applicant_ethnicity-3#156, co-applicant_ethnicity-4#157, co-applicant_ethnicity-5#158, applicant_ethnicity_observed#159, co-applicant_ethnicity_observed#160, applicant_race-1#161, applicant_race-2#162, applicant_race-3#163, applicant_race-4#164, applicant_race-5#165, co-applicant_race-1#166, co-applicant_race-2#167, co-applicant_race-3#168, co-applicant_race-4#169, co-applicant_race-5#170, applicant_race_observed#171, co-applicant_race_observed#172, applicant_sex#173, co-applicant_sex#174, applicant_sex_observed#175, co-applicant_sex_observed#176, applicant_age#177, co-applicant_age#178, applicant_age_above_62#179, co-applicant_age_above_62#180, submission_of_application#181, initially_payable_to_institution#182, aus-1#183, aus-2#184, aus-3#185, aus-4#186, aus-5#187, denial_reason-1#188, denial_reason-2#189, denial_reason-3#190, denial_reason-4#191, tract_population#192, tract_minority_population_percent#193, ffiec_msa_md_median_family_income#194, tract_to_msa_income_percentage#195, tract_owner_occupied_units#196, tract_one_to_four_family_homes#197, tract_median_age_of_housing_units#198]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q6 what does .explain(\"formatted\") tell us about how Spark executes Q5?\n",
    "\n",
    "#1. The table in input[4], denial_reason\n",
    "#2. It Does not involve hash aggregates\n",
    "\n",
    "total_df.explain(\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b284782-aa51-4612-ac10-2cc9d25dc2d9",
   "metadata": {},
   "source": [
    "## Part 3: Grouping Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfd2366-f2a2-4c6e-9b1f-5913a9d422d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q7 what are the average interest rates for Wells Fargo applications for the ten counties where Wells Fargo receives the most applications?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
